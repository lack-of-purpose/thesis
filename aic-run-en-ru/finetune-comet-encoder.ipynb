{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-11T16:16:33.962801Z","iopub.status.busy":"2024-08-11T16:16:33.962127Z","iopub.status.idle":"2024-08-11T16:17:13.210024Z","shell.execute_reply":"2024-08-11T16:17:13.209179Z","shell.execute_reply.started":"2024-08-11T16:16:33.962767Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","import pandas as pd\n","import csv\n","from transformers import XLMRobertaTokenizer\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, encoded_dataset):\n","        self.encoded_dataset = encoded_dataset\n","\n","    def __len__(self):\n","        return len(self.encoded_dataset['labels'])\n","\n","    def __getitem__(self, idx):\n","        item = {\n","            'input_ids': self.encoded_dataset['input_ids'][idx],\n","            'attention_mask': self.encoded_dataset['attention_mask'][idx],\n","            'labels': self.encoded_dataset['labels'][idx]\n","        }\n","        return item\n","\n","tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\")\n","\n","def tokenize_sentences(df):\n","    encoded_sentences = {\n","        'input_ids': [],\n","        'attention_mask': [],\n","        'labels': []\n","    }\n","\n","    for _, row in df.iterrows():\n","        encoded_sent = tokenizer(row['target'], padding='max_length', truncation=True, return_tensors='pt')\n","\n","        encoded_sentences['input_ids'].append(encoded_sent['input_ids'].squeeze())\n","        encoded_sentences['attention_mask'].append(encoded_sent['attention_mask'].squeeze())\n","        encoded_sentences['labels'].append(row['labels'])\n","    \n","    for key in ['input_ids', 'attention_mask']:\n","        encoded_sentences[key] = torch.stack(encoded_sentences[key])\n","    \n","    encoded_sentences['labels'] = torch.tensor(encoded_sentences['labels'], dtype=torch.long)\n","    \n","    return encoded_sentences\n","\n","df_train = pd.read_csv('training--95-tgt.csv', sep='|', quoting=csv.QUOTE_NONE, encoding='utf-8')\n","df_test = pd.read_csv('test--95-tgt.csv', sep='|', encoding='utf-8')\n","df_val = pd.read_csv('validation--95-tgt.csv', sep='|', encoding='utf-8')\n","\n","df_train['labels'] = df_train['labels'].map({'mt': 0, 'human': 1})\n","df_test['labels'] = df_test['labels'].map({'mt': 0, 'human': 1})\n","df_val['labels'] = df_val['labels'].map({'mt': 0, 'human': 1})\n","\n","train_encoded = tokenize_sentences(df_train)\n","valid_encoded = tokenize_sentences(df_val)\n","test_encoded = tokenize_sentences(df_test)\n","\n","train_dataset = CustomDataset(train_encoded)\n","valid_dataset = CustomDataset(valid_encoded)\n","test_dataset = CustomDataset(test_encoded)\n","\n","batch_size = 16\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-11T16:17:19.182505Z","iopub.status.busy":"2024-08-11T16:17:19.181643Z","iopub.status.idle":"2024-08-11T16:17:45.822746Z","shell.execute_reply":"2024-08-11T16:17:45.821799Z","shell.execute_reply.started":"2024-08-11T16:17:19.182465Z"},"trusted":true},"outputs":[],"source":["from comet import download_model, load_from_checkpoint\n","\n","model_path = download_model(\"Unbabel/wmt22-comet-da\")\n","model = load_from_checkpoint(model_path)\n","encoder = model.encoder"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-11T16:17:49.721142Z","iopub.status.busy":"2024-08-11T16:17:49.720269Z","iopub.status.idle":"2024-08-11T16:17:49.732746Z","shell.execute_reply":"2024-08-11T16:17:49.731740Z","shell.execute_reply.started":"2024-08-11T16:17:49.721109Z"},"trusted":true},"outputs":[],"source":["class ClassificationHead(nn.Module):\n","    def __init__(self, input_dim, num_classes):\n","        super(ClassificationHead, self).__init__()\n","        self.classifier = nn.Sequential(\n","            nn.Linear(input_dim, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(input_dim, num_classes, bias=True)\n","        )\n","\n","    def forward(self, x):\n","        return self.classifier(x)\n","\n","classification_head = ClassificationHead(input_dim=1024, num_classes=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-11T16:17:55.009769Z","iopub.status.busy":"2024-08-11T16:17:55.009171Z","iopub.status.idle":"2024-08-11T16:17:55.021156Z","shell.execute_reply":"2024-08-11T16:17:55.020329Z","shell.execute_reply.started":"2024-08-11T16:17:55.009736Z"},"trusted":true},"outputs":[],"source":["class FineTuneModel(nn.Module):\n","    def __init__(self, encoder, classification_head):\n","        super(FineTuneModel, self).__init__()\n","        self.encoder = encoder\n","        self.classification_head = classification_head\n","\n","    def forward(self, input_ids, attention_mask):\n","        encoder_outputs = self.encoder.model(input_ids, attention_mask)\n","\n","        hidden_states = encoder_outputs.last_hidden_state[:, 0, :]\n","        logits = self.classification_head(hidden_states)\n","        \n","        return logits\n","\n","model = FineTuneModel(encoder, classification_head)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-11T16:17:58.898146Z","iopub.status.busy":"2024-08-11T16:17:58.897441Z","iopub.status.idle":"2024-08-11T16:17:58.904427Z","shell.execute_reply":"2024-08-11T16:17:58.903498Z","shell.execute_reply.started":"2024-08-11T16:17:58.898116Z"},"trusted":true},"outputs":[],"source":["for param in model.encoder.parameters():\n","    param.requires_grad = False"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-11T16:20:31.517912Z","iopub.status.busy":"2024-08-11T16:20:31.517208Z","iopub.status.idle":"2024-08-11T16:20:59.569860Z","shell.execute_reply":"2024-08-11T16:20:59.568132Z","shell.execute_reply.started":"2024-08-11T16:20:31.517882Z"},"trusted":true},"outputs":[],"source":["from torcheval.metrics import BinaryAUROC\n","\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=5e-5)\n","val_roc_auc_metric = BinaryAUROC()\n","test_roc_auc_metric = BinaryAUROC()\n","num_epochs = 5\n","\n","#Training\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for batch in train_loader:\n","        input_ids = batch[\"input_ids\"]\n","        attention_mask = batch[\"attention_mask\"]\n","        \n","        optimizer.zero_grad()\n","        outputs = model(input_ids, attention_mask)\n","        labels = torch.nn.functional.one_hot(batch[\"labels\"].long(), num_classes=2).float()\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        running_loss += loss.item()\n","    \n","    avg_train_loss = running_loss / len(train_loader)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {avg_train_loss:.4f}\")\n","        \n","\n","\n","    # Validation\n","    model.eval() \n","    val_loss = 0.0\n","    val_roc_auc_metric.reset()\n","    with torch.no_grad(): \n","        for batch in valid_loader:\n","            input_ids = batch[\"input_ids\"]\n","            attention_mask = batch[\"attention_mask\"]\n","            labels = batch[\"labels\"]\n","\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","            outputs = outputs.transpose(1, 0)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","\n","            probs = torch.softmax(outputs, dim=1)[:, 1] \n","            val_roc_auc_metric.update(probs, labels)\n","\n","    avg_val_loss = val_loss / len(valid_loader)\n","    val_roc_auc = val_roc_auc_metric.compute()\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_roc_auc:.4f}\")\n","    \n","# Testing\n","model.eval()\n","test_loss = 0.0\n","test_roc_auc_metric.reset() \n","with torch.no_grad(): \n","    for batch in test_loader:\n","        input_ids = batch[\"input_ids\"]\n","        attention_mask = batch[\"attention_mask\"]\n","        labels = batch[\"labels\"]\n","\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        outputs = outputs.transpose(1, 0)\n","        loss = criterion(outputs, labels)\n","        test_loss += loss.item()\n","\n","        probs = torch.softmax(outputs, dim=1)[:, 1] \n","        test_roc_auc_metric.update(probs, labels)\n","\n","avg_test_loss = test_loss / len(test_loader)\n","test_roc_auc = test_roc_auc_metric.compute()\n","print(f\"Test Loss: {avg_test_loss:.4f}, Test ROC AUC: {test_roc_auc:.4f}\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4924364,"sourceId":8626218,"sourceType":"datasetVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":4}
